# -*- coding: utf-8 -*-
"""Backpropagation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P2YIwIuk23l6np0iAvTv74K50CqxP0e8
"""

import numpy as np

# ------------------------------------------------
# 1) NEW Inputs, Weights, Biases, Targets
# ------------------------------------------------
x1, x2 = 0.10, 0.20

w1, w2 = 0.12, 0.18     # input → H1
w3, w4 = 0.23, 0.27     # input → H2

w5, w6 = 0.38, 0.44     # H1,H2 → y1
w7, w8 = 0.49, 0.53     # H1,H2 → y2

b1 = 0.30   # hidden bias
b2 = 0.55   # output bias

T1, T2 = 0.05, 0.95     # new targets
lr = 0.5

# ------------------------------------------------
# 2) Activation + derivative
# ------------------------------------------------
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def sigmoid_prime(a):
    return a * (1 - a)

# ------------------------------------------------
# 3) Forward function
# ------------------------------------------------
def forward(x1, x2, w1,w2,w3,w4,w5,w6,w7,w8, b1,b2):

    # Hidden layer nets
    H1_net = x1*w1 + x2*w2 + b1
    H2_net = x1*w3 + x2*w4 + b1

    # Hidden activations
    H1 = sigmoid(H1_net)
    H2 = sigmoid(H2_net)

    # Output layer nets
    y1_net = H1*w5 + H2*w6 + b2
    y2_net = H1*w7 + H2*w8 + b2

    # Output activations
    y1 = sigmoid(y1_net)
    y2 = sigmoid(y2_net)

    return {
        "H1":H1, "H2":H2, "y1":y1, "y2":y2,
        "H1_net":H1_net, "H2_net":H2_net,
        "y1_net":y1_net, "y2_net":y2_net
    }

# ------------------------------------------------
# 4) Forward pass BEFORE update
# ------------------------------------------------
out = forward(x1,x2,w1,w2,w3,w4,w5,w6,w7,w8,b1,b2)

print("\n=== FORWARD PASS (before update) ===")
print(f"H1 = {out['H1']:.8f}, H2 = {out['H2']:.8f}")
print(f"y1 = {out['y1']:.8f}, y2 = {out['y2']:.8f}")

# Error
E1 = 0.5*(T1 - out['y1'])**2
E2 = 0.5*(T2 - out['y2'])**2
E_total = E1 + E2

print(f"Total Error = {E_total:.8f}")

# ------------------------------------------------
# 5) BACKPROP: Output layer deltas
# ------------------------------------------------
delta1 = (out['y1'] - T1) * sigmoid_prime(out['y1'])
delta2 = (out['y2'] - T2) * sigmoid_prime(out['y2'])

print("\n=== BACKPROP (output layer) ===")
print(f"delta1 = {delta1:.8f}, delta2 = {delta2:.8f}")

# Gradients for w5..w8
dw5 = delta1 * out['H1']
dw6 = delta1 * out['H2']
dw7 = delta2 * out['H1']
dw8 = delta2 * out['H2']

# ------------------------------------------------
# 6) BACKPROP: Hidden layer deltas
# ------------------------------------------------
delta_H1 = (delta1*w5 + delta2*w7) * sigmoid_prime(out['H1'])
delta_H2 = (delta1*w6 + delta2*w8) * sigmoid_prime(out['H2'])

print("\n=== BACKPROP (hidden layer) ===")
print(f"delta_H1 = {delta_H1:.8f}, delta_H2 = {delta_H2:.8f}")

# Gradients for w1..w4
dw1 = delta_H1 * x1
dw2 = delta_H1 * x2
dw3 = delta_H2 * x1
dw4 = delta_H2 * x2

# ------------------------------------------------
# 7) UPDATE WEIGHTS
# ------------------------------------------------
w5_new = w5 - lr*dw5
w6_new = w6 - lr*dw6
w7_new = w7 - lr*dw7
w8_new = w8 - lr*dw8

w1_new = w1 - lr*dw1
w2_new = w2 - lr*dw2
w3_new = w3 - lr*dw3
w4_new = w4 - lr*dw4

b1_new = b1 - lr*(delta_H1 + delta_H2)
b2_new = b2 - lr*(delta1 + delta2)

print("\nUpdated weights:")
print(w1_new, w2_new, w3_new, w4_new)
print(w5_new, w6_new, w7_new, w8_new)

# ------------------------------------------------
# 8) Forward pass AFTER update
# ------------------------------------------------
out2 = forward(x1,x2,w1_new,w2_new,w3_new,w4_new,w5_new,w6_new,w7_new,w8_new,b1_new,b2_new)

E_total_after = 0.5*(T1-out2['y1'])**2 + 0.5*(T2-out2['y2'])**2

print("\n=== AFTER UPDATE ===")
print(f"New y1 = {out2['y1']:.8f}, New y2 = {out2['y2']:.8f}")
print(f"New Total Error = {E_total_after:.8f}")